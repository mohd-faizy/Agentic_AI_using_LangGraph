{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8932526",
   "metadata": {},
   "source": [
    "# **üî•LangGraph Core Concepts**\n",
    "\n",
    "- ***Intro***\n",
    "- ***What is LangGraph?***\n",
    "- ***LLM WorkFlows***\n",
    "- ***Prompt Chaining***\n",
    "- ***Routing***\n",
    "- ***Parallelization***\n",
    "- ***Orchestrator Workers***\n",
    "- ***Evaluator Optimizer***\n",
    "- ***Graphs Nodes and Edges***\n",
    "- ***State***\n",
    "- ***Reducers***\n",
    "- ***LangGraph Execution Model***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c484c30b",
   "metadata": {},
   "source": [
    "## üß†**Quick Review**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d30b412",
   "metadata": {},
   "source": [
    "### **1. ü§ñ What Is Agentic AI & Why Do We Need Frameworks?**\n",
    "\n",
    "* **Agentic AI** refers to intelligent systems capable of:\n",
    "\n",
    "  * Making decisions dynamically\n",
    "  * Using tools\n",
    "  * Maintaining memory\n",
    "  * Reacting to new inputs over time\n",
    "* **Building these systems from scratch is hard.**\n",
    "  Manual implementation leads to:\n",
    "\n",
    "  * Complexity\n",
    "  * Glue code\n",
    "  * Poor maintainability\n",
    "\n",
    "#### üõ†Ô∏è Why Use Frameworks Like LangChain or LangGraph?\n",
    "\n",
    "* **LangChain**, **Autogen (Microsoft)**, **CrewAI**, and **LangGraph** simplify development.\n",
    "* LangGraph (built on LangChain) is **tailored for Agentic AI** ‚Äî multi-step, stateful, fault-tolerant systems.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. üîÅ Quick Recap: What Is LangChain?**\n",
    "\n",
    "* **Definition**: An open-source library for building LLM-powered workflows.\n",
    "* Designed for **linear, modular pipelines** (chains of steps).\n",
    "\n",
    "#### üß± Core Building Blocks:\n",
    "\n",
    "* **Models**: Unified API for LLM providers (OpenAI, Hugging Face, Ollama, etc.)\n",
    "* **Prompts**: Templates + formatting for better LLM inputs\n",
    "* **Retrievers**: Fetch data from vector stores for RAG\n",
    "* **Chains**: Sequential steps ‚Äî output of one block is input to the next\n",
    "* **Tools**: Allow LLMs to take actions (e.g., fetch weather)\n",
    "\n",
    "#### ‚úÖ Ideal Use Cases:\n",
    "\n",
    "* Basic chatbots\n",
    "* RAG applications (document-based Q\\&A)\n",
    "* Simple multi-step flows (e.g., summarize ‚Üí extract data)\n",
    "* Connecting LLMs to tools (basic agents)\n",
    "\n",
    "#### ‚ùå Limitations:\n",
    "\n",
    "* Poor support for:\n",
    "\n",
    "  * **Loops**\n",
    "  * **Conditionals**\n",
    "  * **Pausing**\n",
    "  * **Event-driven tasks**\n",
    "  * **State tracking**\n",
    "  * **Complex agent workflows**\n",
    "\n",
    "---\n",
    "\n",
    "### **3. üß™ Case Study: Automated Hiring Workflow**\n",
    "\n",
    "A sample **Agentic AI use case** ‚Äî automating the hiring process ‚Äî is used to show LangChain's limitations and LangGraph's solutions.\n",
    "\n",
    "#### üßæ Steps (Simplified):\n",
    "\n",
    "1. Receive hiring request\n",
    "2. Create job description (JD)\n",
    "3. Human approval\n",
    "4. If rejected ‚Üí revise JD\n",
    "5. Post JD to platforms\n",
    "6. Wait 7 days\n",
    "7. Monitor applications\n",
    "8. If insufficient ‚Üí modify JD ‚Üí loop\n",
    "9. If sufficient ‚Üí parse resumes\n",
    "10. Schedule & conduct interviews\n",
    "11. Send offer or regret emails\n",
    "12. Onboard selected candidate\n",
    "\n",
    "---\n",
    "\n",
    "### **4. ‚ö†Ô∏è Key Challenges with LangChain (and LangGraph's Solutions)**\n",
    "\n",
    "#### **4.1. ‚ùó Challenge: Complex Control Flow**\n",
    "\n",
    "* LangChain supports **linear chains only**.\n",
    "* Complex flows require:\n",
    "\n",
    "  * **Conditionals** (\"if X, do Y\")\n",
    "  * **Loops** (\"retry until pass\")\n",
    "  * **Jumps** (\"go back to step 3\")\n",
    "\n",
    "üí• **Problem**: You must write custom Python glue code.\n",
    "\n",
    "‚úÖ **LangGraph Solution**:\n",
    "\n",
    "* Workflow is modeled as a **graph** ‚Äî a naturally non-linear structure.\n",
    "* Nodes = tasks; edges = transitions (can loop, branch, etc.)\n",
    "* **Zero glue code** ‚Äî just define nodes and edges.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4.2. üíæ Challenge: State Management**\n",
    "\n",
    "* LangChain is **stateless** (except for simple LLM memory).\n",
    "* For Agentic workflows, you need to track:\n",
    "\n",
    "  * JD content\n",
    "  * Approval status\n",
    "  * Application counts\n",
    "  * Resume scores\n",
    "  * Offer status\n",
    "\n",
    "üí• **Problem**: You must manage state manually via global variables.\n",
    "\n",
    "‚úÖ **LangGraph Solution**:\n",
    "\n",
    "* Built-in **shared state object** (like a TypedDict).\n",
    "* Each node can:\n",
    "\n",
    "  * Read from state\n",
    "  * Update the state\n",
    "* **State flows across the entire graph**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4.3. ‚è∏Ô∏è Challenge: Event-Driven Execution**\n",
    "\n",
    "* Many real workflows **pause** (e.g., wait 7 days, wait for human approval).\n",
    "* LangChain assumes fast, continuous runs.\n",
    "\n",
    "üí• **Problem**: No built-in support for long pauses or resume triggers.\n",
    "\n",
    "‚úÖ **LangGraph Solution**:\n",
    "\n",
    "* **Checkpointing**: Save state at any node.\n",
    "* Resume workflow from exact point using external triggers.\n",
    "* Enables **asynchronous, event-based logic**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4.4. üîÑ Challenge: Fault Tolerance**\n",
    "\n",
    "* LangChain: If chain fails mid-way, must restart from the beginning.\n",
    "\n",
    "üí• **Problem**: No built-in retries, no recovery mechanism.\n",
    "\n",
    "‚úÖ **LangGraph Solution**:\n",
    "\n",
    "* **Retry logic** at node-level (e.g., API failure).\n",
    "* **Full recovery** using checkpointed state.\n",
    "* Restarts from failure point ‚Äî no progress lost.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4.5. üßç Challenge: Human-in-the-Loop Integration**\n",
    "\n",
    "* LangChain: Hard to handle long wait times for human decisions.\n",
    "\n",
    "üí• **Problem**: Can't pause workflow without consuming resources.\n",
    "\n",
    "‚úÖ **LangGraph Solution**:\n",
    "\n",
    "* **Pause execution indefinitely** until human input is received.\n",
    "* Resume from same checkpoint.\n",
    "* Useful for approvals, feedback, or manual reviews.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4.6. üîÅ Challenge: Nested Workflows (Subgraphs)**\n",
    "\n",
    "* LangChain does not support running workflows inside other workflows.\n",
    "\n",
    "‚úÖ **LangGraph Solution**:\n",
    "\n",
    "* **Subgraphs**: Treat an entire graph as a node in a parent graph.\n",
    "* Enables:\n",
    "\n",
    "  * Reusable components (e.g., feedback subflow)\n",
    "  * Multi-agent systems with modular graphs\n",
    "\n",
    "---\n",
    "\n",
    "#### **4.7. üîç Challenge: Observability & Debugging**\n",
    "\n",
    "* LangChain (with glue code) has **partial observability**.\n",
    "* LangSmith can't track your custom Python logic.\n",
    "\n",
    "‚úÖ **LangGraph Solution**:\n",
    "\n",
    "* Full integration with **LangSmith**.\n",
    "* All execution, state updates, node transitions are tracked.\n",
    "* Produces a **chronological trace** for debugging and auditing.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. üß≠ When to Use LangChain vs. LangGraph**\n",
    "\n",
    "| Use Case                     | Use LangChain | Use LangGraph |\n",
    "| ---------------------------- | ------------- | ------------- |\n",
    "| Simple chatbots or RAG       | ‚úÖ             | ‚ùå             |\n",
    "| Multi-step sequential chains | ‚úÖ             | ‚ùå             |\n",
    "| Conditional logic, branching | ‚ùå             | ‚úÖ             |\n",
    "| Loops / retries              | ‚ùå             | ‚úÖ             |\n",
    "| Event-driven execution       | ‚ùå             | ‚úÖ             |\n",
    "| Human approval flows         | ‚ùå             | ‚úÖ             |\n",
    "| Multi-agent coordination     | ‚ùå             | ‚úÖ             |\n",
    "| Complex enterprise AI apps   | ‚ùå             | ‚úÖ             |\n",
    "\n",
    "---\n",
    "\n",
    "### **6. üß© Relationship Between LangChain and LangGraph**\n",
    "\n",
    "* **LangGraph is built on top of LangChain.**\n",
    "* LangChain provides **components** (e.g., models, prompts, tools).\n",
    "* LangGraph **orchestrates** those components into a flow.\n",
    "* You typically use **both together**:\n",
    "\n",
    "  * LangChain: LLM calls, tools\n",
    "  * LangGraph: Workflow control, state, logic\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Final Definition:\n",
    "\n",
    "> **\"LangGraph is an orchestration framework that enables you to build stateful, multi-step, and event-driven workflows using LLMs. It's ideal for single-agent and multi-agent Agentic AI applications.\"**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609236f7",
   "metadata": {},
   "source": [
    "## **1. üß≠ What is LangGraph?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac95693",
   "metadata": {},
   "source": [
    "* **LangGraph** is a specialized orchestration framework built for constructing **multi-step**, **stateful**, and **agentic** workflows using Large Language Models (LLMs).\n",
    "* It builds upon **LangChain**, offering enhanced support for:\n",
    "\n",
    "  * Reusability\n",
    "  * Execution control\n",
    "  * Shared memory (State)\n",
    "  * Graph-based workflows\n",
    "\n",
    "### üîß Core Capabilities:\n",
    "\n",
    "* **Graph Representation**:\n",
    "\n",
    "  * Converts your LLM workflow into a **graph**, where:\n",
    "\n",
    "    * **Nodes** = individual tasks (LLM calls, tools, logic)\n",
    "    * **Edges** = flow of execution between tasks\n",
    "\n",
    "* **Key Features**:\n",
    "\n",
    "  * ‚úÖ **Parallel Execution** ‚Äì Multiple tasks can run simultaneously\n",
    "  * üîÅ **Looping** ‚Äì Enables iterative workflows with feedback or retry mechanisms\n",
    "  * üåø **Branching** ‚Äì Routes execution based on conditions in shared State\n",
    "  * üíæ **Memory (State)** ‚Äì Persists data across workflow steps\n",
    "  * ‚ôªÔ∏è **Resumability** ‚Äì Restart from point of failure\n",
    "  * üß† **State-awareness** ‚Äì Nodes can read/write to a shared global State\n",
    "\n",
    "### üìå **Best Used For**:\n",
    "\n",
    "* Multi-agent AI systems\n",
    "* Chatbots with long-term memory\n",
    "* Complex decision workflows\n",
    "* Tool-augmented reasoning applications\n",
    "* Evaluator-Optimizer feedback loops\n",
    "\n",
    "> üó£Ô∏è *Quote*:\n",
    "> ‚ÄúLangGraph first represents the LLM workflow as a graph before executing it.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae8fcf7",
   "metadata": {},
   "source": [
    "## **2. üîÅ LLM Workflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927b27b6",
   "metadata": {},
   "source": [
    "### üìå What is an LLM Workflow?\n",
    "\n",
    "* A **step-by-step process** where LLMs, tools, and logic are coordinated to solve a problem.\n",
    "* Can include: `Prompting`, `Decision-making`, `Tools calling`, `Memory access`, `Evaluation`, and feedback.\n",
    "* Supported structures: **linear**, **branched**, **parallel**, **looped**, and **conditional**.\n",
    "\n",
    "\n",
    "### üîÑ Common LLM Workflow Patterns:\n",
    "\n",
    "1. **üß© Prompt Chaining**\n",
    "   \n",
    "   ![prompt](https://github.com/mohd-faizy/Agentic_AI_using_LangGraph_-_MCP/blob/main/01_Foundation_of_AgenticAI/_img/0501.png?raw=true)\n",
    "\n",
    "   * **Concept**: Sequential execution of LLMs where the output of one becomes the input to the next.\n",
    "   * **Example**:\n",
    "\n",
    "     * LLM 1: Generates outline for a blog post.\n",
    "     * LLM 2: Expands outline into full content.\n",
    "   * **Benefit**:\n",
    "\n",
    "     * Enables intermediate checks\n",
    "     * Simplifies complex tasks via decomposition\n",
    "\n",
    "2. **üö¶ Routing**\n",
    "\n",
    "   ![prompt](https://github.com/mohd-faizy/Agentic_AI_using_LangGraph_-_MCP/blob/main/01_Foundation_of_AgenticAI/_img/0502.png?raw=true)\n",
    "\n",
    "   * **Concept**: A central LLM decides the execution path based on input content.\n",
    "   * **Example**:\n",
    "\n",
    "     * In a customer support bot:\n",
    "\n",
    "       * Route \"refund\" questions to a refund agent,\n",
    "       * \"Technical issue\" to tech support,\n",
    "       * \"Product info\" to sales.\n",
    "   * **Benefit**:\n",
    "\n",
    "     * Increases accuracy and efficiency by using specialized agents\n",
    "\n",
    "3. **‚ö° Parallelization**\n",
    "\n",
    "   ![prompt](https://github.com/mohd-faizy/Agentic_AI_using_LangGraph_-_MCP/blob/main/01_Foundation_of_AgenticAI/_img/0503.png?raw=true)\n",
    "\n",
    "   * **Concept**: Splits a task into concurrent subtasks that run in parallel.\n",
    "   * **Example**:\n",
    "\n",
    "     * A content moderation pipeline:\n",
    "\n",
    "       * LLM A checks for offensive language\n",
    "       * LLM B checks for misinformation\n",
    "       * LLM C checks for spam\n",
    "   * **Benefit**:\n",
    "\n",
    "     * Speeds up execution\n",
    "     * Allows for specialized checks in parallel\n",
    "\n",
    "4. **üß† Orchestrator-Worker Pattern**\n",
    "\n",
    "   ![prompt](https://github.com/mohd-faizy/Agentic_AI_using_LangGraph_-_MCP/blob/main/01_Foundation_of_AgenticAI/_img/0504.png?raw=true)\n",
    "\n",
    "   * **Concept**: An ‚Äú`orchestrator`‚Äù LLM dynamically decides what subtasks to run, and assigns them to ‚Äúworker‚Äù nodes.\n",
    "   * **Example**:\n",
    "\n",
    "     * For a complex research query:\n",
    "\n",
    "       * Orchestrator LLM assigns:\n",
    "\n",
    "         * Google Scholar search to one agent\n",
    "         * Wikipedia scan to another\n",
    "         * News summarization to a third\n",
    "   * **Benefit**:\n",
    "\n",
    "     * Flexible task creation at runtime\n",
    "     * Useful for exploratory or open-ended tasks\n",
    "\n",
    "5. **‚ôªÔ∏è Evaluator-Optimizer (Iterative Feedback Loop)**\n",
    "\n",
    "   ![prompt](https://github.com/mohd-faizy/Agentic_AI_using_LangGraph_-_MCP/blob/main/01_Foundation_of_AgenticAI/_img/0505.png?raw=true)\n",
    "\n",
    "   * **Concept**: A generator LLM produces output, and an evaluator LLM critiques and refines it in iterations.\n",
    "   * **Example**:\n",
    "\n",
    "     * Generator writes an email draft\n",
    "     * Evaluator checks tone, clarity, grammar\n",
    "     * If not approved, evaluator gives feedback ‚Üí generator retries\n",
    "   * **Analogy**:\n",
    "\n",
    "     * Like a writer who improves drafts over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047c9ad9",
   "metadata": {},
   "source": [
    "## **3. üîó Graphs, Nodes, and Edges**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e1fd1f",
   "metadata": {},
   "source": [
    "### üîπ **Nodes**\n",
    "\n",
    "* Represent **individual tasks** in the workflow\n",
    "* Each node is typically implemented as a **Python function**\n",
    "  \n",
    "* **Can perform:**\n",
    "  * *Prompting an LLM*\n",
    "  * *Calling an external tool*\n",
    "  * *Running decision logic*\n",
    "  * *Formatting or filtering outputs*\n",
    "\n",
    "### üî∏**Edges**\n",
    "\n",
    "* Define how **data and control flow** between nodes\n",
    "  \n",
    "* Types of edges:\n",
    "  * **Sequential**: One node follows another (A ‚Üí B)\n",
    "  * **Parallel**: Multiple nodes execute concurrently (A ‚Üí B & C)\n",
    "  * **Conditional**: Flow branches based on logic (A ‚Üí B or C)\n",
    "  * **Looping**: Repeats previous nodes (A ‚Üí B ‚Üí A)\n",
    "\n",
    "\n",
    "### üß™ Example: UPSC Essay Website Workflow\n",
    "\n",
    "LangGraph can model this multi-step pipeline:\n",
    "\n",
    "1. Generate a topic for the essay\n",
    "2. User writes the essay\n",
    "3. Essay is collected\n",
    "4. Three evaluations run **in parallel** (clarity, depth, grammar)\n",
    "5. Scores are aggregated\n",
    "6. Decision made: Pass or Fail\n",
    "7. If Failed ‚Üí generate feedback\n",
    "8. Allow user to retry (loop back to step 2)\n",
    "\n",
    "![workflow upse](https://raw.githubusercontent.com/mohd-faizy/Agentic_AI_using_LangGraph_-_MCP/refs/heads/main/01_Foundation_of_AgenticAI/_img/workflow_upse.png)\n",
    "\n",
    "- **NOTE:**\n",
    "  - > In LangGraph each `Node` is a python function behind the scene.\n",
    "  - > Graph in the LangGraph is essentially a set of python function that are inter-connected with each other with the help of edges.\n",
    "\n",
    "\n",
    "**This example demonstrates:**\n",
    "\n",
    "> * Parallel evaluation\n",
    "> * Feedback-based looping\n",
    "> * Stateful memory flow\n",
    "> * Conditional branches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a54223",
   "metadata": {},
   "source": [
    "## **4. üß† State ‚Äì The Memory Backbone of LangGraph**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf21a9e",
   "metadata": {},
   "source": [
    "### üßæ What is State?\n",
    "\n",
    "* In LangGraph, `state` is the shared memory that flows through your workflow - it holds all the data being passed between nodes as your graphs run.\n",
    "\n",
    "  ```python\n",
    "  essay_text: str\n",
    "  topic: str\n",
    "  depth_score: int\n",
    "  language score: int\n",
    "  clarity_score: int\n",
    "  total score: int\n",
    "  feedback: Annotated[list[str], add] # reducer -> add\n",
    "  evaluation round: int\n",
    "  ```\n",
    "\n",
    "* The **state** is:\n",
    "  * A **shared memory** accessible to all nodes.\n",
    "  * **Mutable**, so any node can change it.\n",
    "\n",
    ">> üí° A **shared, mutable dictionary** (`TypedDict`) that flows through the entire graph.\n",
    "  \n",
    "* Each `Node`:\n",
    "  * **Reads** from State to get context\n",
    "  * **Writes** to State to update or pass results\n",
    "\n",
    "### üîë Why It Matters:\n",
    "\n",
    "* Enables **context sharing** across steps\n",
    "* Makes workflows **stateful**, like agents that remember conversation history\n",
    "* Allows for **data-driven routing** and decisions\n",
    "* Stores tool results, memory values, chat history, intermediate outputs\n",
    "\n",
    "### üí° Example Use Cases:\n",
    "\n",
    "* Maintain conversation memory across multiple user turns\n",
    "* Store search results to reuse in another node\n",
    "* Accumulate reasoning chains or document citations\n",
    "\n",
    "> üó£Ô∏è *Quote*:\n",
    "> ‚ÄúState is the shared memory that flows through your workflow. It holds all the data being passed between nodes as your graph runs.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85f7c9f",
   "metadata": {},
   "source": [
    "## **5. üîÑ Reducers in LangGraph**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0b8356",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è **What Are Reducers?**\n",
    "\n",
    "- Reducers in **LangGraph** define how updates from `Nodes` are applied to the shared state.\n",
    "- Each key in the state can have its own reducer, which determines whether new data `replaces`, `merges`, or `adds` to the existing value.\n",
    "\n",
    "> Think of them like a **funnel or controller**:\n",
    "\n",
    "> They decide how to **combine multiple inputs into one** output at a node.\n",
    "\n",
    "\n",
    "\n",
    "### ‚ùì **Why Are Reducers Needed?**\n",
    "\n",
    "LangGraph supports **parallel execution**, meaning **multiple paths** can run at the same time and return outputs.\n",
    "When these paths **converge**, LangGraph needs to know:\n",
    "\n",
    "‚û°Ô∏è **How should we merge these different outputs?**\n",
    "This is the problem reducers solve.\n",
    "\n",
    "\n",
    "\n",
    "### ‚úÖ **Problems That Reducers Solve**\n",
    "\n",
    "#### üîπ **Chatbot Example**:\n",
    "\n",
    "* Messages overwrite each other ‚Üí **context is lost**.\n",
    "* E.g., If user says:\n",
    "  ‚ÄúHi, my name is Nitesh‚Äù ‚Üí later asks ‚ÄúWhat‚Äôs my name?‚Äù\n",
    "  ‚ùå Bot won‚Äôt know, if messages were **replaced**.\n",
    "* ‚úÖ Use a reducer to **add messages to history** ‚û°Ô∏è maintains full conversation context.\n",
    "\n",
    "\n",
    "\n",
    "#### üîπ **UPSC Essay Example**:\n",
    "\n",
    "* A student writes an essay ‚Üí receives feedback ‚Üí rewrites.\n",
    "* If each `essay_text` update **replaces** the previous one:\n",
    "  ‚ùå All earlier drafts are lost.\n",
    "* ‚úÖ Use a reducer to **merge drafts or track versions** ‚û°Ô∏è see the evolution of thinking.\n",
    "\n",
    "\n",
    "#### üîπ **LangGraph Voting Agent Example**:\n",
    "\n",
    "* 3 agents analyze a document and return:\n",
    "\n",
    "  ```python\n",
    "  [\"Good summary\", \"Okay summary\", \"Great summary\"]\n",
    "  ```\n",
    "* ‚ùå Overwriting would lose 2 of them.\n",
    "* ‚úÖ Reducer can:\n",
    "\n",
    "  * Combine them: `\"Good. Okay. Great.\"`\n",
    "  * Or select the best one using logic or scoring.\n",
    "\n",
    "\n",
    "### ‚öôÔ∏è **How Reducers Work**\n",
    "\n",
    "Reducers define **how each state field is updated**:\n",
    "\n",
    "* **Replace**: Overwrite previous value.\n",
    "  *Example*: `\"name\": \"Nitesh\"` replaces `\"name\": \"John\"`\n",
    "\n",
    "* **Add**: Append to a list or sequence.\n",
    "  *Example*: Adding messages to chat history.\n",
    "\n",
    "* **Merge**: Combine two dictionaries or objects.\n",
    "  *Example*: Merging new tool outputs with existing results.\n",
    "\n",
    "> üîë You can set a **custom reducer per key** in your state ‚Äî giving precise control.\n",
    "\n",
    "\n",
    "### üß© **When to Use Reducers**\n",
    "\n",
    "Use reducers when:\n",
    "\n",
    "* üîÄ You're handling **parallel branches**.\n",
    "* üìú You want **to keep history or track changes**.\n",
    "* üß† You need to **combine outputs from multiple agents/nodes**.\n",
    "\n",
    "> Even before coding, understanding reducers helps you **design smarter workflows** in LangGraph.\n",
    "\n",
    "\n",
    "### üí° \n",
    "\n",
    "| Without Reducers ‚ùå    | With Reducers ‚úÖ              |\n",
    "| ----------------------- | ----------------------------- |\n",
    "| Data gets overwritten   | Data is merged or accumulated |\n",
    "| Context is lost         | Context is preserved          |\n",
    "| Parallel paths conflict | Parallel paths are unified    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3c4d48",
   "metadata": {},
   "source": [
    "## **6. ‚õìÔ∏èü¶ú LangGraph Execution Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dd90d2",
   "metadata": {},
   "source": [
    "- ‚≠ê ***LangGraph's execution model explains how workflows run under the hood.***\n",
    "- ‚≠ê ***Inspired by **Google Pregel**, a system for large-scale graph processing.***\n",
    "\n",
    "\n",
    "\n",
    "### 1Ô∏è‚É£ Graph Definition\n",
    "\n",
    "* First, **define the graph**, which includes:\n",
    "\n",
    "  * **The State Schema**: A special Python ***\"typed dictionary\"*** that holds shared data.\n",
    "  * **Nodes** (function that perform tasks).\n",
    "  * **Edges** (which node connect to which).\n",
    "\n",
    "---\n",
    "\n",
    "### 2Ô∏è‚É£ Compilation Phase\n",
    "\n",
    "* we call `compile()` function on `StateGraph`.\n",
    "* After defining the graph, it goes through **compilation** to ensure:\n",
    "  * **Logical correctness** of the graph structure.\n",
    "  * No issues like **orphan nodes**.\n",
    "\n",
    "---\n",
    "\n",
    "### 3Ô∏è‚É£ Execution Phase\n",
    "\n",
    "#### ‚≠ï ***Invocation***\n",
    "\n",
    "* we run the graph with `.invoke(initial_state)`.\n",
    "* Start by **providing an initial state to the first node**.\n",
    "* This triggers the graph execution.\n",
    "‚≠ï#### ‚≠ï ***Node Activation & Partial Updates***\n",
    "\n",
    "* Each node:\n",
    "\n",
    "  * Runs its associated Python function.\n",
    "  * **Partially updates the shared state** after completing its task.\n",
    "\n",
    "#### ‚≠ï ***Message Passing***\n",
    "\n",
    "* The **updated state is automatically passed** to the next node via edges.\n",
    "* This triggers activation of the next node, forming a chain reaction.\n",
    "\n",
    "#### ‚≠ï ***Supersteps***\n",
    "\n",
    "* A **superstep** = one round of node activations and state updates.\n",
    "* Allows for **parallel execution**:\n",
    "\n",
    "  * A single node can send outputs to multiple nodes.\n",
    "  * All receiving nodes execute **simultaneously** in that superstep.\n",
    "* Parallel outputs are merged using **reducers**.\n",
    "\n",
    "#### ‚≠ï ***Automation***\n",
    "\n",
    "* No need to manually:\n",
    "\n",
    "  * Trigger nodes.\n",
    "  * Pass state between them.\n",
    "* LangGraph handles this **automatically**.\n",
    "\n",
    "#### ‚≠ï ***Stopping Condition***\n",
    "\n",
    "* Workflow execution **ends when**:\n",
    "\n",
    "  * **No active nodes remain**, and\n",
    "  * **No messages are in transit** between nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90f6614",
   "metadata": {},
   "source": [
    "# ‚ùì**LangGraph FAQs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88899b35",
   "metadata": {},
   "source": [
    "#### ‚ùì What is LangGraph and what is its primary function?\n",
    "\n",
    "* LangGraph is an orchestration framework for building intelligent, **stateful**, and **multi-step** LLM workflows.\n",
    "* It represents workflows as **graphs**, where **nodes** are tasks and **edges** define the flow of execution, enabling behaviors like **loops**, **branching**, and **parallelism**.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ùì How does LangGraph represent an LLM workflow, and what do the nodes and edges signify?\n",
    "\n",
    "* LangGraph represents an LLM workflow as a **graph**, similar to a flowchart.\n",
    "* **Nodes** represent individual tasks (like LLM calls or tool usage), while **edges** determine the direction and order of execution between those tasks.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ùì Name and briefly describe two common LLM workflow patterns discussed in the material.\n",
    "\n",
    "* **Prompt Chaining**: Sequentially calls an LLM multiple times, passing outputs as inputs to subsequent calls; useful for breaking down complex problems.\n",
    "* **Routing**: Uses an LLM to make decisions and direct queries to the most appropriate tool or sub-model based on context.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ùì What is the concept of `State` in LangGraph, and why is it crucial for LLM workflows?\n",
    "\n",
    "* The **State** is a shared, mutable memory that flows through the workflow and carries data between nodes.\n",
    "* It is crucial because it allows each node to access and modify relevant data, enabling complex and evolving workflows.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ùì How do nodes interact with the shared `State` in LangGraph during execution?\n",
    "\n",
    "* Each node receives the entire **current State** as input when it runs.\n",
    "* It performs its logic, potentially **modifies the State**, and passes the updated version to the next node.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ùì Explain the purpose of `Reducers` in LangGraph concerning the shared State.\n",
    "\n",
    "* **Reducers** define how updates from nodes are applied to specific keys in the State (e.g., replace, add, merge).\n",
    "* They help avoid unintended overwrites and enable custom update behavior, ensuring **data integrity**.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ùì Provide an example scenario where using a `Reducer` other than replacement for the State update would be beneficial.\n",
    "\n",
    "* In a **chatbot** workflow, if each message replaces the previous one, past context is lost.\n",
    "* Using an **\"add\" reducer** appends new messages, preserving the full conversation history.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ùì What is `Message Passing` in the context of LangGraph's execution model?\n",
    "\n",
    "* It is the **automatic propagation** of the updated State from one node to the next along edges.\n",
    "* This triggers the execution of subsequent nodes without manual intervention.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ùì What is a `Superstep` in LangGraph, and why is it called a `superstep` instead of just a **step**?\n",
    "\n",
    "* A **Superstep** refers to a round of execution in which multiple nodes may run **in parallel**.\n",
    "* It‚Äôs called \"super\" because it can encapsulate **many parallel steps** within a single logical phase.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ùì Describe the three main phases of LangGraph's execution model.\n",
    "\n",
    "* **Graph Definition**: Define nodes, edges, and the initial State.\n",
    "* **Compilation**: Validate the structure and logic of the graph (e.g., ensure no orphaned nodes).\n",
    "* **Execution**: Run the graph starting with an initial State, passing messages and updating State until all activity stops."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agentic_AI_using_LangGraph_-_MCP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
