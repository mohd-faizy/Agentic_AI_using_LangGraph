{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8932526",
   "metadata": {},
   "source": [
    "# **🔥LangGraph Core Concepts**\n",
    "\n",
    "- ***Intro***\n",
    "- ***What is LangGraph?***\n",
    "- ***LLM WorkFlows***\n",
    "- ***Prompt Chaining***\n",
    "- ***Routing***\n",
    "- ***Parallelization***\n",
    "- ***Orchestrator Workers***\n",
    "- ***Evaluator Optimizer***\n",
    "- ***Graphs Nodes and Edges***\n",
    "- ***State***\n",
    "- ***Reducers***\n",
    "- ***LangGraph Execution Model***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c484c30b",
   "metadata": {},
   "source": [
    "## 🧠**Quick Review**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d30b412",
   "metadata": {},
   "source": [
    "### **1. 🤖 What Is Agentic AI & Why Do We Need Frameworks?**\n",
    "\n",
    "* **Agentic AI** refers to intelligent systems capable of:\n",
    "\n",
    "  * Making decisions dynamically\n",
    "  * Using tools\n",
    "  * Maintaining memory\n",
    "  * Reacting to new inputs over time\n",
    "* **Building these systems from scratch is hard.**\n",
    "  Manual implementation leads to:\n",
    "\n",
    "  * Complexity\n",
    "  * Glue code\n",
    "  * Poor maintainability\n",
    "\n",
    "#### 🛠️ Why Use Frameworks Like LangChain or LangGraph?\n",
    "\n",
    "* **LangChain**, **Autogen (Microsoft)**, **CrewAI**, and **LangGraph** simplify development.\n",
    "* LangGraph (built on LangChain) is **tailored for Agentic AI** — multi-step, stateful, fault-tolerant systems.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. 🔁 Quick Recap: What Is LangChain?**\n",
    "\n",
    "* **Definition**: An open-source library for building LLM-powered workflows.\n",
    "* Designed for **linear, modular pipelines** (chains of steps).\n",
    "\n",
    "#### 🧱 Core Building Blocks:\n",
    "\n",
    "* **Models**: Unified API for LLM providers (OpenAI, Hugging Face, Ollama, etc.)\n",
    "* **Prompts**: Templates + formatting for better LLM inputs\n",
    "* **Retrievers**: Fetch data from vector stores for RAG\n",
    "* **Chains**: Sequential steps — output of one block is input to the next\n",
    "* **Tools**: Allow LLMs to take actions (e.g., fetch weather)\n",
    "\n",
    "#### ✅ Ideal Use Cases:\n",
    "\n",
    "* Basic chatbots\n",
    "* RAG applications (document-based Q\\&A)\n",
    "* Simple multi-step flows (e.g., summarize → extract data)\n",
    "* Connecting LLMs to tools (basic agents)\n",
    "\n",
    "#### ❌ Limitations:\n",
    "\n",
    "* Poor support for:\n",
    "\n",
    "  * **Loops**\n",
    "  * **Conditionals**\n",
    "  * **Pausing**\n",
    "  * **Event-driven tasks**\n",
    "  * **State tracking**\n",
    "  * **Complex agent workflows**\n",
    "\n",
    "---\n",
    "\n",
    "### **3. 🧪 Case Study: Automated Hiring Workflow**\n",
    "\n",
    "A sample **Agentic AI use case** — automating the hiring process — is used to show LangChain's limitations and LangGraph's solutions.\n",
    "\n",
    "#### 🧾 Steps (Simplified):\n",
    "\n",
    "1. Receive hiring request\n",
    "2. Create job description (JD)\n",
    "3. Human approval\n",
    "4. If rejected → revise JD\n",
    "5. Post JD to platforms\n",
    "6. Wait 7 days\n",
    "7. Monitor applications\n",
    "8. If insufficient → modify JD → loop\n",
    "9. If sufficient → parse resumes\n",
    "10. Schedule & conduct interviews\n",
    "11. Send offer or regret emails\n",
    "12. Onboard selected candidate\n",
    "\n",
    "---\n",
    "\n",
    "### **4. ⚠️ Key Challenges with LangChain (and LangGraph's Solutions)**\n",
    "\n",
    "#### **4.1. ❗ Challenge: Complex Control Flow**\n",
    "\n",
    "* LangChain supports **linear chains only**.\n",
    "* Complex flows require:\n",
    "\n",
    "  * **Conditionals** (\"if X, do Y\")\n",
    "  * **Loops** (\"retry until pass\")\n",
    "  * **Jumps** (\"go back to step 3\")\n",
    "\n",
    "💥 **Problem**: You must write custom Python glue code.\n",
    "\n",
    "✅ **LangGraph Solution**:\n",
    "\n",
    "* Workflow is modeled as a **graph** — a naturally non-linear structure.\n",
    "* Nodes = tasks; edges = transitions (can loop, branch, etc.)\n",
    "* **Zero glue code** — just define nodes and edges.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4.2. 💾 Challenge: State Management**\n",
    "\n",
    "* LangChain is **stateless** (except for simple LLM memory).\n",
    "* For Agentic workflows, you need to track:\n",
    "\n",
    "  * JD content\n",
    "  * Approval status\n",
    "  * Application counts\n",
    "  * Resume scores\n",
    "  * Offer status\n",
    "\n",
    "💥 **Problem**: You must manage state manually via global variables.\n",
    "\n",
    "✅ **LangGraph Solution**:\n",
    "\n",
    "* Built-in **shared state object** (like a TypedDict).\n",
    "* Each node can:\n",
    "\n",
    "  * Read from state\n",
    "  * Update the state\n",
    "* **State flows across the entire graph**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4.3. ⏸️ Challenge: Event-Driven Execution**\n",
    "\n",
    "* Many real workflows **pause** (e.g., wait 7 days, wait for human approval).\n",
    "* LangChain assumes fast, continuous runs.\n",
    "\n",
    "💥 **Problem**: No built-in support for long pauses or resume triggers.\n",
    "\n",
    "✅ **LangGraph Solution**:\n",
    "\n",
    "* **Checkpointing**: Save state at any node.\n",
    "* Resume workflow from exact point using external triggers.\n",
    "* Enables **asynchronous, event-based logic**.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4.4. 🔄 Challenge: Fault Tolerance**\n",
    "\n",
    "* LangChain: If chain fails mid-way, must restart from the beginning.\n",
    "\n",
    "💥 **Problem**: No built-in retries, no recovery mechanism.\n",
    "\n",
    "✅ **LangGraph Solution**:\n",
    "\n",
    "* **Retry logic** at node-level (e.g., API failure).\n",
    "* **Full recovery** using checkpointed state.\n",
    "* Restarts from failure point — no progress lost.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4.5. 🧍 Challenge: Human-in-the-Loop Integration**\n",
    "\n",
    "* LangChain: Hard to handle long wait times for human decisions.\n",
    "\n",
    "💥 **Problem**: Can't pause workflow without consuming resources.\n",
    "\n",
    "✅ **LangGraph Solution**:\n",
    "\n",
    "* **Pause execution indefinitely** until human input is received.\n",
    "* Resume from same checkpoint.\n",
    "* Useful for approvals, feedback, or manual reviews.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4.6. 🔁 Challenge: Nested Workflows (Subgraphs)**\n",
    "\n",
    "* LangChain does not support running workflows inside other workflows.\n",
    "\n",
    "✅ **LangGraph Solution**:\n",
    "\n",
    "* **Subgraphs**: Treat an entire graph as a node in a parent graph.\n",
    "* Enables:\n",
    "\n",
    "  * Reusable components (e.g., feedback subflow)\n",
    "  * Multi-agent systems with modular graphs\n",
    "\n",
    "---\n",
    "\n",
    "#### **4.7. 🔍 Challenge: Observability & Debugging**\n",
    "\n",
    "* LangChain (with glue code) has **partial observability**.\n",
    "* LangSmith can't track your custom Python logic.\n",
    "\n",
    "✅ **LangGraph Solution**:\n",
    "\n",
    "* Full integration with **LangSmith**.\n",
    "* All execution, state updates, node transitions are tracked.\n",
    "* Produces a **chronological trace** for debugging and auditing.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. 🧭 When to Use LangChain vs. LangGraph**\n",
    "\n",
    "| Use Case                     | Use LangChain | Use LangGraph |\n",
    "| ---------------------------- | ------------- | ------------- |\n",
    "| Simple chatbots or RAG       | ✅             | ❌             |\n",
    "| Multi-step sequential chains | ✅             | ❌             |\n",
    "| Conditional logic, branching | ❌             | ✅             |\n",
    "| Loops / retries              | ❌             | ✅             |\n",
    "| Event-driven execution       | ❌             | ✅             |\n",
    "| Human approval flows         | ❌             | ✅             |\n",
    "| Multi-agent coordination     | ❌             | ✅             |\n",
    "| Complex enterprise AI apps   | ❌             | ✅             |\n",
    "\n",
    "---\n",
    "\n",
    "### **6. 🧩 Relationship Between LangChain and LangGraph**\n",
    "\n",
    "* **LangGraph is built on top of LangChain.**\n",
    "* LangChain provides **components** (e.g., models, prompts, tools).\n",
    "* LangGraph **orchestrates** those components into a flow.\n",
    "* You typically use **both together**:\n",
    "\n",
    "  * LangChain: LLM calls, tools\n",
    "  * LangGraph: Workflow control, state, logic\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Final Definition:\n",
    "\n",
    "> **\"LangGraph is an orchestration framework that enables you to build stateful, multi-step, and event-driven workflows using LLMs. It's ideal for single-agent and multi-agent Agentic AI applications.\"**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609236f7",
   "metadata": {},
   "source": [
    "## **1. 🧭 What is LangGraph?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac95693",
   "metadata": {},
   "source": [
    "* **LangGraph** is a specialized orchestration framework built for constructing **multi-step**, **stateful**, and **agentic** workflows using Large Language Models (LLMs).\n",
    "* It builds upon **LangChain**, offering enhanced support for:\n",
    "\n",
    "  * Reusability\n",
    "  * Execution control\n",
    "  * Shared memory (State)\n",
    "  * Graph-based workflows\n",
    "\n",
    "### 🔧 Core Capabilities:\n",
    "\n",
    "* **Graph Representation**:\n",
    "\n",
    "  * Converts your LLM workflow into a **graph**, where:\n",
    "\n",
    "    * **Nodes** = individual tasks (LLM calls, tools, logic)\n",
    "    * **Edges** = flow of execution between tasks\n",
    "\n",
    "* **Key Features**:\n",
    "\n",
    "  * ✅ **Parallel Execution** – Multiple tasks can run simultaneously\n",
    "  * 🔁 **Looping** – Enables iterative workflows with feedback or retry mechanisms\n",
    "  * 🌿 **Branching** – Routes execution based on conditions in shared State\n",
    "  * 💾 **Memory (State)** – Persists data across workflow steps\n",
    "  * ♻️ **Resumability** – Restart from point of failure\n",
    "  * 🧠 **State-awareness** – Nodes can read/write to a shared global State\n",
    "\n",
    "### 📌 **Best Used For**:\n",
    "\n",
    "* Multi-agent AI systems\n",
    "* Chatbots with long-term memory\n",
    "* Complex decision workflows\n",
    "* Tool-augmented reasoning applications\n",
    "* Evaluator-Optimizer feedback loops\n",
    "\n",
    "> 🗣️ *Quote*:\n",
    "> “LangGraph first represents the LLM workflow as a graph before executing it.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae8fcf7",
   "metadata": {},
   "source": [
    "## **2. 🔁 LLM Workflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927b27b6",
   "metadata": {},
   "source": [
    "### 📌 What is an LLM Workflow?\n",
    "\n",
    "* A **step-by-step process** where LLMs, tools, and logic are coordinated to solve a problem.\n",
    "* Can include: `Prompting`, `Decision-making`, `Tools calling`, `Memory access`, `Evaluation`, and feedback.\n",
    "* Supported structures: **linear**, **branched**, **parallel**, **looped**, and **conditional**.\n",
    "\n",
    "\n",
    "### 🔄 Common LLM Workflow Patterns:\n",
    "\n",
    "1. **🧩 Prompt Chaining**\n",
    "   \n",
    "   ![prompt](https://github.com/mohd-faizy/Agentic_AI_using_LangGraph_-_MCP/blob/main/01_Foundation_of_AgenticAI/_img/0501.png?raw=true)\n",
    "\n",
    "   * **Concept**: Sequential execution of LLMs where the output of one becomes the input to the next.\n",
    "   * **Example**:\n",
    "\n",
    "     * LLM 1: Generates outline for a blog post.\n",
    "     * LLM 2: Expands outline into full content.\n",
    "   * **Benefit**:\n",
    "\n",
    "     * Enables intermediate checks\n",
    "     * Simplifies complex tasks via decomposition\n",
    "\n",
    "2. **🚦 Routing**\n",
    "\n",
    "   ![prompt](https://github.com/mohd-faizy/Agentic_AI_using_LangGraph_-_MCP/blob/main/01_Foundation_of_AgenticAI/_img/0502.png?raw=true)\n",
    "\n",
    "   * **Concept**: A central LLM decides the execution path based on input content.\n",
    "   * **Example**:\n",
    "\n",
    "     * In a customer support bot:\n",
    "\n",
    "       * Route \"refund\" questions to a refund agent,\n",
    "       * \"Technical issue\" to tech support,\n",
    "       * \"Product info\" to sales.\n",
    "   * **Benefit**:\n",
    "\n",
    "     * Increases accuracy and efficiency by using specialized agents\n",
    "\n",
    "3. **⚡ Parallelization**\n",
    "\n",
    "   ![prompt](https://github.com/mohd-faizy/Agentic_AI_using_LangGraph_-_MCP/blob/main/01_Foundation_of_AgenticAI/_img/0503.png?raw=true)\n",
    "\n",
    "   * **Concept**: Splits a task into concurrent subtasks that run in parallel.\n",
    "   * **Example**:\n",
    "\n",
    "     * A content moderation pipeline:\n",
    "\n",
    "       * LLM A checks for offensive language\n",
    "       * LLM B checks for misinformation\n",
    "       * LLM C checks for spam\n",
    "   * **Benefit**:\n",
    "\n",
    "     * Speeds up execution\n",
    "     * Allows for specialized checks in parallel\n",
    "\n",
    "4. **🧠 Orchestrator-Worker Pattern**\n",
    "\n",
    "   ![prompt](https://github.com/mohd-faizy/Agentic_AI_using_LangGraph_-_MCP/blob/main/01_Foundation_of_AgenticAI/_img/0504.png?raw=true)\n",
    "\n",
    "   * **Concept**: An “`orchestrator`” LLM dynamically decides what subtasks to run, and assigns them to “worker” nodes.\n",
    "   * **Example**:\n",
    "\n",
    "     * For a complex research query:\n",
    "\n",
    "       * Orchestrator LLM assigns:\n",
    "\n",
    "         * Google Scholar search to one agent\n",
    "         * Wikipedia scan to another\n",
    "         * News summarization to a third\n",
    "   * **Benefit**:\n",
    "\n",
    "     * Flexible task creation at runtime\n",
    "     * Useful for exploratory or open-ended tasks\n",
    "\n",
    "5. **♻️ Evaluator-Optimizer (Iterative Feedback Loop)**\n",
    "\n",
    "   ![prompt](https://github.com/mohd-faizy/Agentic_AI_using_LangGraph_-_MCP/blob/main/01_Foundation_of_AgenticAI/_img/0505.png?raw=true)\n",
    "\n",
    "   * **Concept**: A generator LLM produces output, and an evaluator LLM critiques and refines it in iterations.\n",
    "   * **Example**:\n",
    "\n",
    "     * Generator writes an email draft\n",
    "     * Evaluator checks tone, clarity, grammar\n",
    "     * If not approved, evaluator gives feedback → generator retries\n",
    "   * **Analogy**:\n",
    "\n",
    "     * Like a writer who improves drafts over time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047c9ad9",
   "metadata": {},
   "source": [
    "## **3. 🔗 Graphs, Nodes, and Edges**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e1fd1f",
   "metadata": {},
   "source": [
    "### 🔹 **Nodes**\n",
    "\n",
    "* Represent **individual tasks** in the workflow\n",
    "* Each node is typically implemented as a **Python function**\n",
    "  \n",
    "* **Can perform:**\n",
    "  * *Prompting an LLM*\n",
    "  * *Calling an external tool*\n",
    "  * *Running decision logic*\n",
    "  * *Formatting or filtering outputs*\n",
    "\n",
    "### 🔸**Edges**\n",
    "\n",
    "* Define how **data and control flow** between nodes\n",
    "  \n",
    "* Types of edges:\n",
    "  * **Sequential**: One node follows another (A → B)\n",
    "  * **Parallel**: Multiple nodes execute concurrently (A → B & C)\n",
    "  * **Conditional**: Flow branches based on logic (A → B or C)\n",
    "  * **Looping**: Repeats previous nodes (A → B → A)\n",
    "\n",
    "\n",
    "### 🧪 Example: UPSC Essay Website Workflow\n",
    "\n",
    "LangGraph can model this multi-step pipeline:\n",
    "\n",
    "1. Generate a topic for the essay\n",
    "2. User writes the essay\n",
    "3. Essay is collected\n",
    "4. Three evaluations run **in parallel** (clarity, depth, grammar)\n",
    "5. Scores are aggregated\n",
    "6. Decision made: Pass or Fail\n",
    "7. If Failed → generate feedback\n",
    "8. Allow user to retry (loop back to step 2)\n",
    "\n",
    "![workflow upse](https://raw.githubusercontent.com/mohd-faizy/Agentic_AI_using_LangGraph_-_MCP/refs/heads/main/01_Foundation_of_AgenticAI/_img/workflow_upse.png)\n",
    "\n",
    "- **NOTE:**\n",
    "  - > In LangGraph each `Node` is a python function behind the scene.\n",
    "  - > Graph in the LangGraph is essentially a set of python function that are inter-connected with each other with the help of edges.\n",
    "\n",
    "\n",
    "**This example demonstrates:**\n",
    "\n",
    "> * Parallel evaluation\n",
    "> * Feedback-based looping\n",
    "> * Stateful memory flow\n",
    "> * Conditional branches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a54223",
   "metadata": {},
   "source": [
    "## **4. 🧠 State – The Memory Backbone of LangGraph**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf21a9e",
   "metadata": {},
   "source": [
    "### 🧾 What is State?\n",
    "\n",
    "* In LangGraph, `state` is the shared memory that flows through your workflow - it holds all the data being passed between nodes as your graphs run.\n",
    "\n",
    "  ```python\n",
    "  essay_text: str\n",
    "  topic: str\n",
    "  depth_score: int\n",
    "  language score: int\n",
    "  clarity_score: int\n",
    "  total score: int\n",
    "  feedback: Annotated[list[str], add] # reducer -> add\n",
    "  evaluation round: int\n",
    "  ```\n",
    "\n",
    "* The **state** is:\n",
    "  * A **shared memory** accessible to all nodes.\n",
    "  * **Mutable**, so any node can change it.\n",
    "\n",
    ">> 💡 A **shared, mutable dictionary** (`TypedDict`) that flows through the entire graph.\n",
    "  \n",
    "* Each `Node`:\n",
    "  * **Reads** from State to get context\n",
    "  * **Writes** to State to update or pass results\n",
    "\n",
    "### 🔑 Why It Matters:\n",
    "\n",
    "* Enables **context sharing** across steps\n",
    "* Makes workflows **stateful**, like agents that remember conversation history\n",
    "* Allows for **data-driven routing** and decisions\n",
    "* Stores tool results, memory values, chat history, intermediate outputs\n",
    "\n",
    "### 💡 Example Use Cases:\n",
    "\n",
    "* Maintain conversation memory across multiple user turns\n",
    "* Store search results to reuse in another node\n",
    "* Accumulate reasoning chains or document citations\n",
    "\n",
    "> 🗣️ *Quote*:\n",
    "> “State is the shared memory that flows through your workflow. It holds all the data being passed between nodes as your graph runs.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85f7c9f",
   "metadata": {},
   "source": [
    "## **5. 🔄 Reducers in LangGraph**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0b8356",
   "metadata": {},
   "source": [
    "### ⚙️ **What Are Reducers?**\n",
    "\n",
    "- Reducers in **LangGraph** define how updates from `Nodes` are applied to the shared state.\n",
    "- Each key in the state can have its own reducer, which determines whether new data `replaces`, `merges`, or `adds` to the existing value.\n",
    "\n",
    "> Think of them like a **funnel or controller**:\n",
    "\n",
    "> They decide how to **combine multiple inputs into one** output at a node.\n",
    "\n",
    "\n",
    "\n",
    "### ❓ **Why Are Reducers Needed?**\n",
    "\n",
    "LangGraph supports **parallel execution**, meaning **multiple paths** can run at the same time and return outputs.\n",
    "When these paths **converge**, LangGraph needs to know:\n",
    "\n",
    "➡️ **How should we merge these different outputs?**\n",
    "This is the problem reducers solve.\n",
    "\n",
    "\n",
    "\n",
    "### ✅ **Problems That Reducers Solve**\n",
    "\n",
    "#### 🔹 **Chatbot Example**:\n",
    "\n",
    "* Messages overwrite each other → **context is lost**.\n",
    "* E.g., If user says:\n",
    "  “Hi, my name is Nitesh” → later asks “What’s my name?”\n",
    "  ❌ Bot won’t know, if messages were **replaced**.\n",
    "* ✅ Use a reducer to **add messages to history** ➡️ maintains full conversation context.\n",
    "\n",
    "\n",
    "\n",
    "#### 🔹 **UPSC Essay Example**:\n",
    "\n",
    "* A student writes an essay → receives feedback → rewrites.\n",
    "* If each `essay_text` update **replaces** the previous one:\n",
    "  ❌ All earlier drafts are lost.\n",
    "* ✅ Use a reducer to **merge drafts or track versions** ➡️ see the evolution of thinking.\n",
    "\n",
    "\n",
    "#### 🔹 **LangGraph Voting Agent Example**:\n",
    "\n",
    "* 3 agents analyze a document and return:\n",
    "\n",
    "  ```python\n",
    "  [\"Good summary\", \"Okay summary\", \"Great summary\"]\n",
    "  ```\n",
    "* ❌ Overwriting would lose 2 of them.\n",
    "* ✅ Reducer can:\n",
    "\n",
    "  * Combine them: `\"Good. Okay. Great.\"`\n",
    "  * Or select the best one using logic or scoring.\n",
    "\n",
    "\n",
    "### ⚙️ **How Reducers Work**\n",
    "\n",
    "Reducers define **how each state field is updated**:\n",
    "\n",
    "* **Replace**: Overwrite previous value.\n",
    "  *Example*: `\"name\": \"Nitesh\"` replaces `\"name\": \"John\"`\n",
    "\n",
    "* **Add**: Append to a list or sequence.\n",
    "  *Example*: Adding messages to chat history.\n",
    "\n",
    "* **Merge**: Combine two dictionaries or objects.\n",
    "  *Example*: Merging new tool outputs with existing results.\n",
    "\n",
    "> 🔑 You can set a **custom reducer per key** in your state — giving precise control.\n",
    "\n",
    "\n",
    "### 🧩 **When to Use Reducers**\n",
    "\n",
    "Use reducers when:\n",
    "\n",
    "* 🔀 You're handling **parallel branches**.\n",
    "* 📜 You want **to keep history or track changes**.\n",
    "* 🧠 You need to **combine outputs from multiple agents/nodes**.\n",
    "\n",
    "> Even before coding, understanding reducers helps you **design smarter workflows** in LangGraph.\n",
    "\n",
    "\n",
    "### 💡 \n",
    "\n",
    "| Without Reducers ❌    | With Reducers ✅              |\n",
    "| ----------------------- | ----------------------------- |\n",
    "| Data gets overwritten   | Data is merged or accumulated |\n",
    "| Context is lost         | Context is preserved          |\n",
    "| Parallel paths conflict | Parallel paths are unified    |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3c4d48",
   "metadata": {},
   "source": [
    "## **6. ⛓️🦜 LangGraph Execution Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dd90d2",
   "metadata": {},
   "source": [
    "- ⭐ ***LangGraph's execution model explains how workflows run under the hood.***\n",
    "- ⭐ ***Inspired by **Google Pregel**, a system for large-scale graph processing.***\n",
    "\n",
    "\n",
    "\n",
    "### 1️⃣ Graph Definition\n",
    "\n",
    "* First, **define the graph**, which includes:\n",
    "\n",
    "  * **The State Schema**: A special Python ***\"typed dictionary\"*** that holds shared data.\n",
    "  * **Nodes** (function that perform tasks).\n",
    "  * **Edges** (which node connect to which).\n",
    "\n",
    "---\n",
    "\n",
    "### 2️⃣ Compilation Phase\n",
    "\n",
    "* we call `compile()` function on `StateGraph`.\n",
    "* After defining the graph, it goes through **compilation** to ensure:\n",
    "  * **Logical correctness** of the graph structure.\n",
    "  * No issues like **orphan nodes**.\n",
    "\n",
    "---\n",
    "\n",
    "### 3️⃣ Execution Phase\n",
    "\n",
    "#### ⭕ ***Invocation***\n",
    "\n",
    "* we run the graph with `.invoke(initial_state)`.\n",
    "* Start by **providing an initial state to the first node**.\n",
    "* This triggers the graph execution.\n",
    "⭕#### ⭕ ***Node Activation & Partial Updates***\n",
    "\n",
    "* Each node:\n",
    "\n",
    "  * Runs its associated Python function.\n",
    "  * **Partially updates the shared state** after completing its task.\n",
    "\n",
    "#### ⭕ ***Message Passing***\n",
    "\n",
    "* The **updated state is automatically passed** to the next node via edges.\n",
    "* This triggers activation of the next node, forming a chain reaction.\n",
    "\n",
    "#### ⭕ ***Supersteps***\n",
    "\n",
    "* A **superstep** = one round of node activations and state updates.\n",
    "* Allows for **parallel execution**:\n",
    "\n",
    "  * A single node can send outputs to multiple nodes.\n",
    "  * All receiving nodes execute **simultaneously** in that superstep.\n",
    "* Parallel outputs are merged using **reducers**.\n",
    "\n",
    "#### ⭕ ***Automation***\n",
    "\n",
    "* No need to manually:\n",
    "\n",
    "  * Trigger nodes.\n",
    "  * Pass state between them.\n",
    "* LangGraph handles this **automatically**.\n",
    "\n",
    "#### ⭕ ***Stopping Condition***\n",
    "\n",
    "* Workflow execution **ends when**:\n",
    "\n",
    "  * **No active nodes remain**, and\n",
    "  * **No messages are in transit** between nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90f6614",
   "metadata": {},
   "source": [
    "# ❓**LangGraph FAQs**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88899b35",
   "metadata": {},
   "source": [
    "#### ❓ What is LangGraph and what is its primary function?\n",
    "\n",
    "* LangGraph is an orchestration framework for building intelligent, **stateful**, and **multi-step** LLM workflows.\n",
    "* It represents workflows as **graphs**, where **nodes** are tasks and **edges** define the flow of execution, enabling behaviors like **loops**, **branching**, and **parallelism**.\n",
    "\n",
    "---\n",
    "\n",
    "#### ❓ How does LangGraph represent an LLM workflow, and what do the nodes and edges signify?\n",
    "\n",
    "* LangGraph represents an LLM workflow as a **graph**, similar to a flowchart.\n",
    "* **Nodes** represent individual tasks (like LLM calls or tool usage), while **edges** determine the direction and order of execution between those tasks.\n",
    "\n",
    "---\n",
    "\n",
    "#### ❓ Name and briefly describe two common LLM workflow patterns discussed in the material.\n",
    "\n",
    "* **Prompt Chaining**: Sequentially calls an LLM multiple times, passing outputs as inputs to subsequent calls; useful for breaking down complex problems.\n",
    "* **Routing**: Uses an LLM to make decisions and direct queries to the most appropriate tool or sub-model based on context.\n",
    "\n",
    "---\n",
    "\n",
    "#### ❓ What is the concept of `State` in LangGraph, and why is it crucial for LLM workflows?\n",
    "\n",
    "* The **State** is a shared, mutable memory that flows through the workflow and carries data between nodes.\n",
    "* It is crucial because it allows each node to access and modify relevant data, enabling complex and evolving workflows.\n",
    "\n",
    "---\n",
    "\n",
    "#### ❓ How do nodes interact with the shared `State` in LangGraph during execution?\n",
    "\n",
    "* Each node receives the entire **current State** as input when it runs.\n",
    "* It performs its logic, potentially **modifies the State**, and passes the updated version to the next node.\n",
    "\n",
    "---\n",
    "\n",
    "#### ❓ Explain the purpose of `Reducers` in LangGraph concerning the shared State.\n",
    "\n",
    "* **Reducers** define how updates from nodes are applied to specific keys in the State (e.g., replace, add, merge).\n",
    "* They help avoid unintended overwrites and enable custom update behavior, ensuring **data integrity**.\n",
    "\n",
    "---\n",
    "\n",
    "#### ❓ Provide an example scenario where using a `Reducer` other than replacement for the State update would be beneficial.\n",
    "\n",
    "* In a **chatbot** workflow, if each message replaces the previous one, past context is lost.\n",
    "* Using an **\"add\" reducer** appends new messages, preserving the full conversation history.\n",
    "\n",
    "---\n",
    "\n",
    "#### ❓ What is `Message Passing` in the context of LangGraph's execution model?\n",
    "\n",
    "* It is the **automatic propagation** of the updated State from one node to the next along edges.\n",
    "* This triggers the execution of subsequent nodes without manual intervention.\n",
    "\n",
    "---\n",
    "\n",
    "#### ❓ What is a `Superstep` in LangGraph, and why is it called a `superstep` instead of just a **step**?\n",
    "\n",
    "* A **Superstep** refers to a round of execution in which multiple nodes may run **in parallel**.\n",
    "* It’s called \"super\" because it can encapsulate **many parallel steps** within a single logical phase.\n",
    "\n",
    "---\n",
    "\n",
    "#### ❓ Describe the three main phases of LangGraph's execution model.\n",
    "\n",
    "* **Graph Definition**: Define nodes, edges, and the initial State.\n",
    "* **Compilation**: Validate the structure and logic of the graph (e.g., ensure no orphaned nodes).\n",
    "* **Execution**: Run the graph starting with an initial State, passing messages and updating State until all activity stops."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agentic_AI_using_LangGraph_-_MCP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
